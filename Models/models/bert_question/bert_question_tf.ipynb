{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_question_tf.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNFvEdvJCkJ0++Rajr69cHu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C49OZoO3vtmT","executionInfo":{"status":"ok","timestamp":1618093713235,"user_tz":-120,"elapsed":1006,"user":{"displayName":"Andrea Grendene","photoUrl":"","userId":"06402570928856140792"}},"outputId":"acf87b43-6fbb-4c59-d6fc-d8dffcac64b1"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rogbCXhJ-itn","executionInfo":{"status":"ok","timestamp":1618093721148,"user_tz":-120,"elapsed":8045,"user":{"displayName":"Andrea Grendene","photoUrl":"","userId":"06402570928856140792"}},"outputId":"228eb4e6-3b87-46d8-edc2-6c0009761495"},"source":["!pip install -q tensorflow-text\n","!pip install -q tf-models-official\n","!pip install tensorflow-determinism"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-determinism in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMIbBuPy-wed","executionInfo":{"status":"ok","timestamp":1618109457542,"user_tz":-120,"elapsed":125992,"user":{"displayName":"Andrea Grendene","photoUrl":"","userId":"06402570928856140792"}},"outputId":"3ac4ee28-f0e7-4669-e6ad-cdaff0401938"},"source":["general_settings = {\n","    \"seed\": 2021,\n","    \"batch_size\": 32,\n","    \"validation_split\": 0.15,\n","    \"destination_path\": \"/content/gdrive/MyDrive/Colab Notebooks/output\",\n","    \"threshold\": 0.5\n","}\n","\n","import os\n","from typing import List, Dict, Any, Tuple\n","import json\n","import shutil\n","from sklearn.metrics import accuracy_score, classification_report\n","import random\n","import numpy as np\n","\n","\"\"\"# Set seed to prevent non-determinism\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","os.environ['TF_CUDNN_DETERMINISTIC']='1'\n","os.environ['PYTHONHASHSEED']=str(general_settings['seed'])\n","random.seed(general_settings['seed'])\n","np.random.seed(general_settings['seed'])\"\"\"\n","\n","import tensorflow as tf\n","tf.random.set_seed(general_settings['seed'])\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from official.nlp import optimization  # to create AdamW optmizer\n","from tensorflow.data import Dataset\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.models import load_model\n","\n","import matplotlib.pyplot as plt\n","\n","\"\"\"from fwd9m.tensorflow import enable_determinism\n","enable_determinism()\"\"\"\n","\n","tf.get_logger().setLevel('ERROR')\n","\n","\n","\n","# Support function to avoid code repetition, get questions and labels lists\n","def get_lists_from_elements(elements_list: List[Dict[str, Any]]) -> Tuple[List[str], List[int]]:\n","    questions = []\n","    labels = []\n","    for element in elements_list:\n","        if element['question']:\n","            questions.append(element['question'])\n","        else:\n","            questions.append(element['NNQT_question'])\n","        if 'has_answer' in element and element['has_answer'] == False:\n","            labels.append(0)\n","        else:\n","            labels.append(1)\n","    return questions, labels\n","\n","# Load dataset data\n","with open(\"/content/gdrive/MyDrive/Colab Notebooks/data/LC_QuAD_2_train_balanced_with_embeddings_no_dp.json\", \"r\") as json_file:\n","    train_data = json.load(json_file)\n","    train_questions, train_labels = get_lists_from_elements(train_data)\n","with open(\"/content/gdrive/MyDrive/Colab Notebooks/data/LC_QuAD_2_valid_balanced_with_embeddings_no_dp.json\", \"r\") as json_file:\n","    valid_data = json.load(json_file)\n","    valid_questions, valid_labels = get_lists_from_elements(valid_data)\n","with open(\"/content/gdrive/MyDrive/Colab Notebooks/data/LC_QuAD_2_test_balanced_with_embeddings.json\", \"r\") as json_file:\n","    test_data = json.load(json_file)\n","    test_questions, test_labels = get_lists_from_elements(test_data)\n","\n","# Create datasets\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","\"\"\"train_set_length = len(train_questions)\n","val_set_length = int(train_set_length * general_settings['validation_split'])\"\"\"\n","train_set = Dataset.from_tensor_slices((train_questions, train_labels))\n","\n","val_set = Dataset.from_tensor_slices((valid_questions, valid_labels))\n","\n","\"\"\"train_set = train_set.shuffle(train_set_length, seed=general_settings['seed'])\n","val_set = train_set.take(val_set_length)\n","train_set = train_set.skip(val_set_length)\"\"\"\n","train_set = train_set.batch(general_settings['batch_size'])\n","val_set = val_set.batch(general_settings['batch_size'])\n","train_set = train_set.cache().prefetch(buffer_size=AUTOTUNE)\n","val_set = val_set.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","test_set = Dataset.from_tensor_slices((test_questions, test_labels))\n","test_set = test_set.batch(general_settings['batch_size'])\n","test_set = test_set.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","# Build model\n","\"\"\"tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\"\"\"\n","tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n","\n","def build_classifier_model():\n","  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","  # Preprocess text input\n","  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n","  encoder_inputs = preprocessing_layer(text_input)\n","  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n","  outputs = encoder(encoder_inputs)\n","  # 'pooled_output' is the [CLS] token\n","  net = outputs['pooled_output']\n","  net = tf.keras.layers.Dropout(0.3)(net)\n","  net = tf.keras.layers.Dense(768, activation=None)(net)\n","  net = tf.keras.layers.Dense(768, activation=None)(net)\n","  net = tf.keras.layers.Dense(768, activation=None)(net)\n","  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n","  return tf.keras.Model(text_input, net)\n","\n","# Define BCE loss function and accuracy metric\n","loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","metrics = tf.metrics.BinaryAccuracy(threshold=general_settings['threshold'])\n","\n","epochs = 70\n","steps_per_epoch = tf.data.experimental.cardinality(train_set).numpy()\n","num_train_steps = steps_per_epoch * epochs\n","# Number of steps (10%) of fixed learning rate before linear decay\n","num_warmup_steps = int(0.1*num_train_steps)\n","\n","# For Small BERT fine-tuning is recommended a low learning rate (between 2e-5 and 5e-5)\n","init_lr = 6e-6\n","# Optimizer is AdamW, a version of Adam that uses weights decay instead of moments\n","\"\"\"optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                          num_train_steps=num_train_steps,\n","                                          num_warmup_steps=num_warmup_steps,\n","                                          optimizer_type='adamw')\"\"\"\n","optimizer = Adam(init_lr)\n","# Build model and load information\n","classifier_model = build_classifier_model()\n","classifier_model.compile(optimizer=optimizer,\n","                         loss=loss,\n","                         metrics=metrics)\n","callbacks = [\n","    ModelCheckpoint(\n","        # Path where to save the model. The two parameters below mean that we will overwrite\n","        # the current checkpoint if and only if the `val_loss` score has improved.\n","        # The saved model name will include the current epoch.\n","        filepath=general_settings['destination_path'] + \"/bert_question\",\n","        save_best_only=True,  # Only save a model if `val_loss` has improved.\n","        monitor=\"val_loss\",\n","        verbose=1,\n","    ),\n","  EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","]\n","\n","# Freeze BERT training\n","for w in classifier_model.get_layer('BERT_encoder').weights:\n","    w._trainable = False\n","\n","# Train\n","print(f'Training model with {tfhub_handle_encoder}')\n","\"\"\"history = classifier_model.fit(x=train_set,\n","                               validation_data=val_set,\n","                               shuffle=False,\n","                               epochs=epochs,\n","                               callbacks=callbacks)\"\"\"\n","\n","# Load model\n","classifier_model = load_model(general_settings['destination_path'] + \"/bert_question\")\n","\n","# Test\n","y_pred = classifier_model.predict(test_set).tolist()\n","# Get answer label from y_pred, using a Sigmoid to normalize the result\n","y_final_pred = []\n","for pred in y_pred:\n","  normalized_pred = tf.sigmoid(pred)\n","  if normalized_pred > general_settings['threshold']:\n","    y_final_pred.append(1)\n","  else:\n","    y_final_pred.append(0)\n","\n","# Print final metrics\n","print('Classification Report:')\n","print(classification_report(test_labels, y_final_pred, labels=[1,0], digits=4))\n","\n","# Write predictions to file\n","with open(general_settings['destination_path'] + \"/bert_question/model_predictions.txt\", \"w\") as answers_file:\n","    answers_file.write(str(y_final_pred))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1     0.6275    0.5016    0.5575       319\n","           0     0.5632    0.6833    0.6175       300\n","\n","    accuracy                         0.5897       619\n","   macro avg     0.5953    0.5925    0.5875       619\n","weighted avg     0.5963    0.5897    0.5866       619\n","\n"],"name":"stdout"}]}]}