{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_question_answer_tf.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C49OZoO3vtmT","executionInfo":{"status":"ok","timestamp":1618282300712,"user_tz":-120,"elapsed":15891,"user":{"displayName":"Andrea Grendene","photoUrl":"","userId":"06402570928856140792"}},"outputId":"27b43f14-a0c7-4602-deaf-1cc5f16c2fc4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rogbCXhJ-itn","executionInfo":{"status":"ok","timestamp":1618282320868,"user_tz":-120,"elapsed":35770,"user":{"displayName":"Andrea Grendene","photoUrl":"","userId":"06402570928856140792"}},"outputId":"7f139c10-5ca1-4a4a-dd0c-19456f9fd477"},"source":["!pip install -q tensorflow-text\n","!pip install -q tf-models-official\n","!pip install tensorflow-determinism"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 3.4MB 8.3MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 8.6MB/s \n","\u001b[K     |████████████████████████████████| 706kB 27.4MB/s \n","\u001b[K     |████████████████████████████████| 174kB 50.9MB/s \n","\u001b[K     |████████████████████████████████| 37.6MB 80kB/s \n","\u001b[K     |████████████████████████████████| 1.2MB 56.0MB/s \n","\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n","\u001b[K     |████████████████████████████████| 358kB 52.0MB/s \n","\u001b[K     |████████████████████████████████| 102kB 15.5MB/s \n","\u001b[K     |████████████████████████████████| 645kB 50.9MB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorflow-determinism\n","  Downloading https://files.pythonhosted.org/packages/76/56/79d74f25b326d8719753172496abc524980fa67d1d98bb247021376e370a/tensorflow-determinism-0.3.0.tar.gz\n","Building wheels for collected packages: tensorflow-determinism\n","  Building wheel for tensorflow-determinism (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-determinism: filename=tensorflow_determinism-0.3.0-cp37-none-any.whl size=9158 sha256=88aad1e18faa76c1455a5733f4966a77dcb6af628b1dec6e4784799ae8ca86a1\n","  Stored in directory: /root/.cache/pip/wheels/66/c3/18/13959a90d3e0d10182a99866d6ff4d0119e9daed6ce014b54c\n","Successfully built tensorflow-determinism\n","Installing collected packages: tensorflow-determinism\n","Successfully installed tensorflow-determinism-0.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hMIbBuPy-wed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618282473310,"user_tz":-120,"elapsed":97478,"user":{"displayName":"Andrea Grendene","photoUrl":"","userId":"06402570928856140792"}},"outputId":"6350f492-25a0-4e2b-9a2b-341e428fe4b2"},"source":["general_settings = {\n","    \"seed\": 2021,\n","    \"batch_size\": 32,\n","    \"validation_split\": 0.15,\n","    \"destination_path\": \"/content/gdrive/MyDrive/Colab Notebooks/output\",\n","    \"threshold\": 0.5\n","}\n","\n","import os\n","from typing import List, Dict, Any, Tuple\n","import json\n","import shutil\n","from sklearn.metrics import accuracy_score, classification_report\n","import random\n","import numpy as np\n","\n","\"\"\"# Set seed to prevent non-determinism\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","os.environ['TF_CUDNN_DETERMINISTIC']='1'\n","os.environ['PYTHONHASHSEED']=str(general_settings['seed'])\n","random.seed(general_settings['seed'])\n","np.random.seed(general_settings['seed'])\"\"\"\n","\n","import tensorflow as tf\n","tf.random.set_seed(general_settings['seed'])\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from official.nlp import optimization  # to create AdamW optmizer\n","from tensorflow.data import Dataset\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.models import load_model\n","\n","import matplotlib.pyplot as plt\n","\n","\"\"\"from fwd9m.tensorflow import enable_determinism\n","enable_determinism()\"\"\"\n","\n","tf.get_logger().setLevel('ERROR')\n","\n","\n","\n","# Support function to avoid code repetition, get questions_answers and labels lists\n","def get_lists_from_elements(elements_list: List[Dict[str, Any]]) -> Tuple[List[str], List[int]]:\n","    questions_answers = []\n","    labels = []\n","    for element in elements_list:\n","        answer = element['deeppavlov_answer']\n","        if element['question']:\n","            questions_answers.append(element['question'] + \" [SEP] \" + answer)\n","        else:\n","            questions_answers.append(element['NNQT_question'] + \" [SEP] \" + answer)\n","        if 'has_answer' in element and element['has_answer'] == False:\n","            labels.append(0)\n","        else:\n","            labels.append(1)\n","    return questions_answers, labels\n","\n","# Load dataset data\n","with open(\"/content/gdrive/MyDrive/Colab Notebooks/data/LC_QuAD_2_train_balanced_with_embeddings_no_dp.json\", \"r\") as json_file:\n","    train_data = json.load(json_file)\n","    train_questions_answers, train_labels = get_lists_from_elements(train_data)\n","with open(\"/content/gdrive/MyDrive/Colab Notebooks/data/LC_QuAD_2_valid_balanced_with_embeddings_no_dp.json\", \"r\") as json_file:\n","    valid_data = json.load(json_file)\n","    valid_questions_answers, valid_labels = get_lists_from_elements(valid_data)\n","with open(\"/content/gdrive/MyDrive/Colab Notebooks/data/LC_QuAD_2_test_balanced_with_embeddings.json\", \"r\") as json_file:\n","    test_data = json.load(json_file)\n","    test_questions_answers, test_labels = get_lists_from_elements(test_data)\n","\n","# Create datasets\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","\"\"\"train_set_length = len(train_questions)\n","val_set_length = int(train_set_length * general_settings['validation_split'])\"\"\"\n","train_set = Dataset.from_tensor_slices((train_questions_answers, train_labels))\n","\n","val_set = Dataset.from_tensor_slices((valid_questions_answers, valid_labels))\n","\n","\"\"\"train_set = train_set.shuffle(train_set_length, seed=general_settings['seed'])\n","val_set = train_set.take(val_set_length)\n","train_set = train_set.skip(val_set_length)\"\"\"\n","train_set = train_set.batch(general_settings['batch_size'])\n","val_set = val_set.batch(general_settings['batch_size'])\n","train_set = train_set.cache().prefetch(buffer_size=AUTOTUNE)\n","val_set = val_set.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","test_set = Dataset.from_tensor_slices((test_questions_answers, test_labels))\n","test_set = test_set.batch(general_settings['batch_size'])\n","test_set = test_set.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","# Build model\n","\"\"\"tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\"\"\"\n","tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n","tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n","\n","def build_classifier_model():\n","  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n","  # Preprocess text input\n","  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n","  encoder_inputs = preprocessing_layer(text_input)\n","  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n","  outputs = encoder(encoder_inputs)\n","  # 'pooled_output' is the [CLS] token\n","  net = outputs['pooled_output']\n","  net = tf.keras.layers.Dropout(0.25)(net)\n","  net = tf.keras.layers.Dense(768, activation=None)(net)\n","  net = tf.keras.layers.Dense(768, activation=None)(net)\n","  net = tf.keras.layers.Dense(768, activation=None)(net)\n","  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n","  return tf.keras.Model(text_input, net)\n","\n","# Define BCE loss function and accuracy metric\n","loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","metrics = tf.metrics.BinaryAccuracy(threshold=general_settings['threshold'])\n","\n","epochs = 70\n","steps_per_epoch = tf.data.experimental.cardinality(train_set).numpy()\n","num_train_steps = steps_per_epoch * epochs\n","# Number of steps (10%) of fixed learning rate before linear decay\n","num_warmup_steps = int(0.1*num_train_steps)\n","\n","# For BERT fine-tuning is recommended a low learning rate (between 2e-5 and 5e-5)\n","init_lr = 4e-6\n","# Optimizer is AdamW, a version of Adam that uses weights decay instead of moments\n","\"\"\"optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                          num_train_steps=num_train_steps,\n","                                          num_warmup_steps=num_warmup_steps,\n","                                          optimizer_type='adamw')\"\"\"\n","optimizer = Adam(init_lr)\n","# Build model and load information\n","classifier_model = build_classifier_model()\n","classifier_model.compile(optimizer=optimizer,\n","                         loss=loss,\n","                         metrics=metrics)\n","callbacks = [\n","    ModelCheckpoint(\n","        # Path where to save the model. The two parameters below mean that we will overwrite\n","        # the current checkpoint if and only if the `val_loss` score has improved.\n","        # The saved model name will include the current epoch.\n","        filepath=general_settings['destination_path'] + \"/bert_question_answer\",\n","        save_best_only=True,  # Only save a model if `val_loss` has improved.\n","        monitor=\"val_loss\",\n","        verbose=1,\n","    ),\n","  EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","]\n","\n","# Freeze BERT training\n","\"\"\"for w in classifier_model.get_layer('BERT_encoder').weights:\n","    w._trainable = False\"\"\"\n","\n","# Train\n","print(f'Training model with {tfhub_handle_encoder}')\n","history = classifier_model.fit(x=train_set,\n","                               validation_data=val_set,\n","                               shuffle=False,\n","                               epochs=epochs,\n","                               callbacks=callbacks)\n","\n","# Load model\n","classifier_model = load_model(general_settings['destination_path'] + \"/bert_question_answer\")\n","\n","# Test\n","y_pred = classifier_model.predict(test_set).tolist()\n","# Get answer label from y_pred, using a Sigmoid to normalize the result\n","y_final_pred = []\n","for pred in y_pred:\n","  normalized_pred = tf.sigmoid(pred)\n","  if normalized_pred > general_settings['threshold']:\n","    y_final_pred.append(1)\n","  else:\n","    y_final_pred.append(0)\n","\n","# Print final metrics\n","print('Classification Report:')\n","print(classification_report(test_labels, y_final_pred, labels=[1,0], digits=4))\n","\n","# Write predictions to file\n","with open(general_settings['destination_path'] + \"/bert_question_answer/model_predictions.txt\", \"w\") as answers_file:\n","    answers_file.write(str(y_final_pred))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1     0.5727    0.7774    0.6596       319\n","           0     0.6183    0.3833    0.4733       300\n","\n","    accuracy                         0.5864       619\n","   macro avg     0.5955    0.5804    0.5664       619\n","weighted avg     0.5948    0.5864    0.5693       619\n","\n"],"name":"stdout"}]}]}